{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Data\n",
    "\n",
    "In many \"real world\" situations, the data that we want to use come in multiple\n",
    "files. We often need to combine these files into a single DataFrame to analyze\n",
    "the data. The pandas package provides [various methods for combining\n",
    "DataFrames](http://pandas.pydata.org/pandas-docs/stable/merging.html) including\n",
    "`merge` and `concat`.\n",
    "\n",
    "# Learning Objectives\n",
    "* Learn how to concatenate two DataFrames together (append one dataFrame to a second dataFrame)\n",
    "* Learn how to join two DataFrames together using a uniqueID found in both DataFrames\n",
    "* Learn how to write out a DataFrame to csv using Pandas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work through the examples below, we first need to load the species and\n",
    "surveys files into pandas DataFrames. In iPython:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "surveys_df = pd.read_csv(\"https://ndownloader.figshare.com/files/2292172\",\n",
    "                         keep_default_na=False, na_values=[\"\"])\n",
    "surveys_df\n",
    "\n",
    "       record_id  month  day  year  plot species  sex  hindfoot_length weight\n",
    "0              1      7   16  1977     2      NA    M               32  NaN\n",
    "1              2      7   16  1977     3      NA    M               33  NaN\n",
    "2              3      7   16  1977     2      DM    F               37  NaN\n",
    "3              4      7   16  1977     7      DM    M               36  NaN\n",
    "4              5      7   16  1977     3      DM    M               35  NaN\n",
    "...          ...    ...  ...   ...   ...     ...  ...              ...  ...\n",
    "35544      35545     12   31  2002    15      AH  NaN              NaN  NaN\n",
    "35545      35546     12   31  2002    15      AH  NaN              NaN  NaN\n",
    "35546      35547     12   31  2002    10      RM    F               15   14\n",
    "35547      35548     12   31  2002     7      DO    M               36   51\n",
    "35548      35549     12   31  2002     5     NaN  NaN              NaN  NaN\n",
    "\n",
    "[35549 rows x 9 columns]\n",
    "\n",
    "species_df = pd.read_csv('https://ndownloader.figshare.com/files/3299483',\n",
    "                         keep_default_na=False, na_values=[\"\"])\n",
    "species_df\n",
    "  species_id             genus          species     taxa\n",
    "0          AB        Amphispiza        bilineata     Bird\n",
    "1          AH  Ammospermophilus          harrisi   Rodent\n",
    "2          AS        Ammodramus       savannarum     Bird\n",
    "3          BA           Baiomys          taylori   Rodent\n",
    "4          CB   Campylorhynchus  brunneicapillus     Bird\n",
    "..        ...               ...              ...      ...\n",
    "49         UP            Pipilo              sp.     Bird\n",
    "50         UR            Rodent              sp.   Rodent\n",
    "51         US           Sparrow              sp.     Bird\n",
    "52         ZL       Zonotrichia       leucophrys     Bird\n",
    "53         ZM           Zenaida         macroura     Bird\n",
    "\n",
    "[54 rows x 4 columns]\n",
    "```\n",
    "\n",
    "Take note that the `read_csv` method we used can take some additional options which\n",
    "we didn't use previously. Many functions in python have a set of options that\n",
    "can be set by the user if needed. In this case, we have told Pandas to assign\n",
    "empty values in our CSV to NaN `keep_default_na=False, na_values=[\"\"]`.\n",
    "[http://pandas.pydata.org/pandas-docs/dev/generated/pandas.io.parsers.read_csv.html](More\n",
    "about all of the read_csv options here.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "os.chdir(\"F:\\Piton\")\n",
    "\n",
    "surveys = pd.read_csv(\"survey2001.csv\")\n",
    "species = pd.read_csv(\"survey2002.csv\")\n",
    "#species_df\n",
    "sur11= surveys[-11:-1].reset_index(drop=True)\n",
    "spec11= species[-11:-1].reset_index(drop=True)\n",
    "# spec11\n",
    "# sur11\n",
    "#spec11.to_csv('out.csv')\n",
    "#sur11\n",
    "# pd.concat([sur11, spec11], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating DataFrames\n",
    "\n",
    "We can use the `concat` function in Pandas to append either columns or rows from\n",
    "one DataFrame to another.  Let's grab two subsets of our data to see how this\n",
    "works.\n",
    "\n",
    "```python\n",
    "# read in first 10 lines of surveys table\n",
    "survey_sub = surveys_df.head(10)\n",
    "# grab the last 10 rows (minus the last one)\n",
    "survey_sub_last10 = surveys_df[-11:-1]\n",
    "#reset the index values to the second dataframe appends properly\n",
    "survey_sub_last10=survey_sub_last10.reset_index(drop=True)\n",
    "# drop=True option avoids adding new index column with old index values\n",
    "```\n",
    "\n",
    "When we concatenate DataFrames, we need to specify the axis. `axis=0` tells\n",
    "Pandas to stack the second DataFrame under the first one. It will automatically\n",
    "detect whether the column names are the same and will stack accordingly.\n",
    "`axis=1` will stack the columns in the second DataFrame to the RIGHT of the\n",
    "first DataFrame. To stack the data vertically, we need to make sure we have the\n",
    "same columns and associated column format in both datasets. When we stack\n",
    "horizonally, we want to make sure what we are doing makes sense (ie the data are\n",
    "related in some way).\n",
    "\n",
    "```python\n",
    "# stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([survey_sub, survey_sub_last10], axis=0)\n",
    "\n",
    "# place the DataFrames side by side\n",
    "horizontal_stack = pd.concat([survey_sub, survey_sub_last10], axis=1)\n",
    "```\n",
    "\n",
    "### Row Index Values and Concat\n",
    "Have a look at the `vertical_stack` dataframe? Notice anything unusual?\n",
    "The row indexes for the two data frames `survey_sub` and `survey_sub_last10`\n",
    "have been repeated. We can reindex the new dataframe using the `reset_index()` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35539</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>SF</td>\n",
       "      <td>M</td>\n",
       "      <td>26.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>37.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>35540</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>PB</td>\n",
       "      <td>F</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35541</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>PB</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>35542</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>PB</td>\n",
       "      <td>F</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35543</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>PB</td>\n",
       "      <td>F</td>\n",
       "      <td>27.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DO</td>\n",
       "      <td>F</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>35544</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>M</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35545</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>AH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>OX</td>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35546</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>15</td>\n",
       "      <td>AH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35547</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>RM</td>\n",
       "      <td>F</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35548</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>DO</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  month   day    year  plot_id species_id  sex  hindfoot_length  \\\n",
       "0       63.0    8.0  19.0  1977.0      3.0         DM    M             35.0   \n",
       "1       64.0    8.0  19.0  1977.0      7.0         DM    M             37.0   \n",
       "2       65.0    8.0  19.0  1977.0      4.0         DM    F             34.0   \n",
       "3       66.0    8.0  19.0  1977.0      4.0         DM    F             35.0   \n",
       "4       67.0    8.0  19.0  1977.0      7.0         DM    M             35.0   \n",
       "5       68.0    8.0  19.0  1977.0      8.0         DO    F             32.0   \n",
       "6       69.0    8.0  19.0  1977.0      2.0         PF    M             15.0   \n",
       "7       70.0    8.0  19.0  1977.0      3.0         OX    F             21.0   \n",
       "8        NaN    NaN   NaN     NaN      NaN        NaN  NaN              NaN   \n",
       "9        NaN    NaN   NaN     NaN      NaN        NaN  NaN              NaN   \n",
       "\n",
       "   weight  record_id  month  day  year  plot_id species_id  sex  \\\n",
       "0    40.0      35539     12   31  2002       15         SF    M   \n",
       "1    48.0      35540     12   31  2002       15         PB    F   \n",
       "2    29.0      35541     12   31  2002       15         PB    F   \n",
       "3    46.0      35542     12   31  2002       15         PB    F   \n",
       "4    36.0      35543     12   31  2002       15         PB    F   \n",
       "5    52.0      35544     12   31  2002       15         US  NaN   \n",
       "6     8.0      35545     12   31  2002       15         AH  NaN   \n",
       "7    22.0      35546     12   31  2002       15         AH  NaN   \n",
       "8     NaN      35547     12   31  2002       10         RM    F   \n",
       "9     NaN      35548     12   31  2002        7         DO    M   \n",
       "\n",
       "   hindfoot_length  weight  \n",
       "0             26.0    68.0  \n",
       "1             26.0    23.0  \n",
       "2             24.0    31.0  \n",
       "3             26.0    29.0  \n",
       "4             27.0    34.0  \n",
       "5              NaN     NaN  \n",
       "6              NaN     NaN  \n",
       "7              NaN     NaN  \n",
       "8             15.0    14.0  \n",
       "9             36.0    51.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "surveys_df = pd.read_csv(\"https://ndownloader.figshare.com/files/2292172\",\n",
    "                         keep_default_na=False, na_values=[\"\"])\n",
    "\n",
    "# read in first 10 lines of surveys table\n",
    "survey_sub = surveys_df.head(70)\n",
    "\n",
    "survey_sub = survey_sub[pd.notnull(survey_sub.weight)].reset_index(drop=True)\n",
    "# grab the last 10 rows (minus the last one)\n",
    "survey_sub_last10 = surveys_df[-11:-1]\n",
    "#reset the index values to the second dataframe appends properly\n",
    "survey_sub_last10=survey_sub_last10.reset_index(drop=True)\n",
    "# drop=True option avoids adding new index column with old index values\n",
    "survey_sub_last10\n",
    "\n",
    "vertical_stack = pd.concat([survey_sub, survey_sub_last10], axis=1)\n",
    "vertical_stack #.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Out Data to CSV\n",
    "\n",
    "We can use the `to_csv` command to do export a DataFrame in CSV format. Note that the code\n",
    "below will by default save the data into the current working directory. We can\n",
    "save it to a different folder by adding the foldername and a slash to the file\n",
    "`vertical_stack.to_csv('foldername/out.csv')`.\n",
    "\n",
    "```python\n",
    "# Write DataFrame to CSV \n",
    "vertical_stack.to_csv('out.csv')\n",
    "```\n",
    "\n",
    "Check out your working directory to make sure the CSV wrote out properly, and\n",
    "that you can open it! If you want, try to bring it back into python to make sure\n",
    "it imports properly.\n",
    "\n",
    "```python\t\n",
    "# for kicks read our output back into python and make sure all looks good\n",
    "newOutput = pd.read_csv('out.csv', keep_default_na=False, na_values=[\"\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "In the data folder, there are two survey data files: `survey2001.csv` and\n",
    "`survey2002.csv`. Read the data into python and combine the files to make one\n",
    "new data frame. Create a plot of average plot weight by year grouped by sex.\n",
    "Export your results as a CSV and make sure it reads back into python properly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>2001</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>40.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>2001</th>\n",
       "      <td>82.333333</td>\n",
       "      <td>47.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>34.583333</td>\n",
       "      <td>43.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>2001</th>\n",
       "      <td>27.500000</td>\n",
       "      <td>33.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>48.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>2001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>2001</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>29.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>2001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>2001</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>46.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>2001</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>48.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>2001</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>40.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>33.250000</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>2001</th>\n",
       "      <td>33.500000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>2001</th>\n",
       "      <td>39.750000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>2001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">17</th>\n",
       "      <th>2001</th>\n",
       "      <td>39.375000</td>\n",
       "      <td>29.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>39.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">18</th>\n",
       "      <th>2001</th>\n",
       "      <td>26.333333</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">19</th>\n",
       "      <th>2001</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>29.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>22.800000</td>\n",
       "      <td>36.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>2001</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">21</th>\n",
       "      <th>2001</th>\n",
       "      <td>28.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>29.400000</td>\n",
       "      <td>34.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">22</th>\n",
       "      <th>2001</th>\n",
       "      <td>28.500000</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>2002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sex                F          M\n",
       "plot year                      \n",
       "1    2001  25.000000  44.000000\n",
       "     2002  35.000000  40.500000\n",
       "2    2001  82.333333  47.166667\n",
       "     2002  34.583333  43.076923\n",
       "3    2001  27.500000  33.500000\n",
       "     2002  25.000000  48.666667\n",
       "4    2001        NaN  35.333333\n",
       "6    2001  28.000000  29.500000\n",
       "7    2001        NaN  36.500000\n",
       "9    2001  44.000000  46.333333\n",
       "11   2001  41.000000  48.333333\n",
       "12   2001  35.000000  40.333333\n",
       "     2002  33.250000  35.500000\n",
       "13   2001  33.500000  12.000000\n",
       "14   2001  39.750000  48.500000\n",
       "15   2001        NaN  22.000000\n",
       "17   2001  39.375000  29.166667\n",
       "     2002  36.000000  39.333333\n",
       "18   2001  26.333333  40.000000\n",
       "     2002  26.750000  38.000000\n",
       "19   2001  16.000000  29.400000\n",
       "     2002  22.800000  36.750000\n",
       "20   2001  29.000000        NaN\n",
       "21   2001  28.250000        NaN\n",
       "     2002  29.400000  34.500000\n",
       "22   2001  28.500000  37.500000\n",
       "     2002  30.000000  45.000000\n",
       "23   2002        NaN  18.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "os.chdir(\"F:\\Piton\")\n",
    "\n",
    "surveys = pd.read_csv(\"survey2001.csv\")\n",
    "species = pd.read_csv(\"survey2002.csv\")\n",
    "#species_df\n",
    "s2001= surveys.head(100)\n",
    "s2002= species.head(100)\n",
    "\n",
    "vertical_stack = pd.concat([s2001, s2002], axis=0)\n",
    "vertical_stack.groupby(['plot', 'year', 'sex'])['wgt'].mean().unstack()\n",
    "\n",
    "# vertical_stack\n",
    "# s_plot = vertical_stack.plot(kind='bar',stacked=False,title=\"Total weight by plot and sex\")\n",
    "# s_plot.set_ylabel(\"wgt\")\n",
    "# s_plot.set_xlabel(\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining DataFrames\n",
    "\n",
    "When we concatenated our DataFrames we simply added them to each other -\n",
    "stacking them either vertically or side by side. Another way to combine\n",
    "DataFrames is to use columns in each dataset that contain common values (a\n",
    "common unique id). Combining DataFrames using a common field is called\n",
    "\"joining\". The columns containing the common values are called \"join key(s)\".\n",
    "Joining DataFrames in this way is often useful when one DataFrame is a \"lookup\n",
    "table\" containing additional data that we want to include in the other. \n",
    "\n",
    "NOTE: This process of joining tables is similar to what we do with tables in an\n",
    "SQL database.\n",
    "\n",
    "For example, the `species.csv` file that we've been working with is a lookup\n",
    "table. This table contains the genus, species and taxa code for 55 species. The\n",
    "species code is unique for each line. These species are identified in our survey\n",
    "data as well using the unique species code. Rather than adding 3 more columns\n",
    "for the genus, species and taxa to each of the 35,549 line Survey data table, we\n",
    "can maintain the shorter table with the species information. When we want to\n",
    "access that information, we can create a query that joins the additional columns\n",
    "of information to the Survey data.\n",
    "\n",
    "Storing data in this way has many benefits including:\n",
    "\n",
    "1. It ensures consistency in the spelling of species attributes (genus, species\n",
    "   and taxa) given each species is only entered once. Imagine the possibilities\n",
    "   for spelling errors when entering the genus and species thousands of times!\n",
    "2. It also makes it easy for us to make changes to the species information once\n",
    "   without having to find each instance of it in the larger survey data.\n",
    "3. It optimizes the size of our data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Two DataFrames \n",
    "\n",
    "To better understand joins, let's grab the first 10 lines of our data as a\n",
    "subset to work with. We'll use the `.head` method to do this. We'll also read\n",
    "in a subset of the species table. \n",
    "\n",
    "```python\n",
    "# read in first 10 lines of surveys table\n",
    "survey_sub = surveys_df.head(10)\n",
    "\n",
    "# import a small subset of the species data designed for this part of the lesson\n",
    "species_sub = pd.read_csv('../data/speciesSubset.csv', keep_default_na=False, na_values=[\"\"])\n",
    "```\n",
    "\n",
    "In this example, `species_sub` is the lookup table containing genus, species, and\n",
    "taxa names that we want to join with the data in `survey_sub` to produce a new\n",
    "DataFrame that contains all of the columns from both `species_df` *and*\n",
    "`survey_df`.\n",
    "\n",
    "\n",
    "## Identifying join keys\n",
    "\n",
    "To identify appropriate join keys we first need to know which field(s) are\n",
    "shared between the files (DataFrames). We might inspect both DataFrames to\n",
    "identify these columns. If we are lucky, both DataFrames will have columns with\n",
    "the same name that also contain the same data. If we are less lucky, we need to\n",
    "identify a (differently-named) column in each DataFrame that contains the same\n",
    "information.\n",
    "\n",
    "```python\n",
    "species_sub.columns\n",
    "\n",
    "Index([u'species_id', u'genus', u'species', u'taxa'], dtype='object')\n",
    "\n",
    "survey_sub.columns\n",
    "\n",
    "Index([u'record_id', u'month', u'day', u'year', u'plot_id', u'species_id',\n",
    "       u'sex', u'hindfoot_length', u'weight'], dtype='object')\n",
    "```\n",
    "\n",
    "In our example, the join key is the column containing the two-letter species\n",
    "identifier, which is called `species_id`.\n",
    "\n",
    "Now that we know the fields with the common species ID attributes in each\n",
    "DataFrame, we are almost ready to join our data. However, since there are\n",
    "[different types of joins](http://blog.codinghorror.com/a-visual-explanation-of-sql-joins/), we\n",
    "also need to decide which type of join makes sense for our analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in first 10 lines of surveys table\n",
    "survey_sub = surveys_df.head(10)\n",
    "\n",
    "# import a small subset of the species data designed for this part of the lesson\n",
    "species_sub = pd.read_csv('../data/speciesSubset.csv', keep_default_na=False, na_values=[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner joins\n",
    "\n",
    "The most common type of join is called an _inner join_. An inner join combines\n",
    "two DataFrames based on a join key and returns a new DataFrame that contains\n",
    "**only** those rows that have matching values in *both* of the original\n",
    "DataFrames. \n",
    "\n",
    "Inner joins yield a DataFrame that contains only rows where the value being\n",
    "joins exists in BOTH tables. An example of an inner join, adapted from [this\n",
    "page](http://blog.codinghorror.com/a-visual-explanation-of-sql-joins/) is below:\n",
    "\n",
    "![Inner join -- courtesy of codinghorror.com](http://blog.codinghorror.com/content/images/uploads/2007/10/6a0120a85dcdae970b012877702708970c-pi.png)\n",
    "\n",
    "The pandas function for performing joins is called `merge` and an Inner join is\n",
    "the default option:  \n",
    "\n",
    "```python\n",
    "merged_inner = pd.merge(left=survey_sub,right=species_sub, left_on='species_id', right_on='species_id')\n",
    "# in this case `species_id` is the only column name in  both dataframes, so if we skippd `left_on`\n",
    "# and `right_on` arguments we would still get the same result\n",
    "\n",
    "# what's the size of the output data?\n",
    "merged_inner.shape\n",
    "merged_inner\n",
    "```\n",
    "\n",
    "**OUTPUT:**\n",
    "\n",
    "```\n",
    "   record_id  month  day  year  plot_id species_id sex  hindfoot_length  \\\n",
    "0          1      7   16  1977        2         NL   M               32   \n",
    "1          2      7   16  1977        3         NL   M               33   \n",
    "2          3      7   16  1977        2         DM   F               37   \n",
    "3          4      7   16  1977        7         DM   M               36   \n",
    "4          5      7   16  1977        3         DM   M               35   \n",
    "5          8      7   16  1977        1         DM   M               37   \n",
    "6          9      7   16  1977        1         DM   F               34   \n",
    "7          7      7   16  1977        2         PE   F              NaN   \n",
    "\n",
    "   weight       genus   species    taxa  \n",
    "0     NaN     Neotoma  albigula  Rodent  \n",
    "1     NaN     Neotoma  albigula  Rodent  \n",
    "2     NaN   Dipodomys  merriami  Rodent  \n",
    "3     NaN   Dipodomys  merriami  Rodent  \n",
    "4     NaN   Dipodomys  merriami  Rodent  \n",
    "5     NaN   Dipodomys  merriami  Rodent  \n",
    "6     NaN   Dipodomys  merriami  Rodent  \n",
    "7     NaN  Peromyscus  eremicus  Rodent  \n",
    "```\n",
    "\n",
    "The result of an inner join of `survey_sub` and `species_sub` is a new DataFrame\n",
    "that contains the combined set of columns from `survey_sub` and `species_sub`. It\n",
    "*only* contains rows that have two-letter species codes that are the same in\n",
    "both the `survey_sub` and `species_sub` DataFrames. In other words, if a row in\n",
    "`survey_sub` has a value of `species_id` that does *not* appear in the `species_id`\n",
    "column of `species`, it will not be included in the DataFrame returned by an\n",
    "inner join.  Similarly, if a row in `species_sub` has a value of `species_id`\n",
    "that does *not* appear in the `species_id` column of `survey_sub`, that row will not\n",
    "be included in the DataFrame returned by an inner join.\n",
    "\n",
    "The two DataFrames that we want to join are passed to the `merge` function using\n",
    "the `left` and `right` argument. The `left_on='species'` argument tells `merge`\n",
    "to use the `species_id` column as the join key from `survey_sub` (the `left`\n",
    "DataFrame). Similarly , the `right_on='species_id'` argument tells `merge` to\n",
    "use the `species_id` column as the join key from `species_sub` (the `right`\n",
    "DataFrame). For inner joins, the order of the `left` and `right` arguments does\n",
    "not matter.\n",
    "\n",
    "The result `merged_inner` DataFrame contains all of the columns from `survey_sub`\n",
    "(record id, month, day, etc.) as well as all the columns from `species_sub`\n",
    "(species_id, genus, species, and taxa).\n",
    "\n",
    "Notice that `merged_inner` has fewer rows than `survey_sub`. This is an\n",
    "indication that there were rows in `surveys_df` with value(s) for `species_id` that\n",
    "do not exist as value(s) for `species_id` in `species_df`.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.merge(left=survey_sub,right=species_sub, left_on='species_id', right_on='species_id')\n",
    "# pd.merge(left=survey_sub,right=species_sub)\n",
    "# survey_sub.merge(species_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"F:\\Piton\")\n",
    "\n",
    "species_sub = pd.read_csv(\"species.csv\", keep_default_na=False, na_values=[\"\"])\n",
    "survey_sub= pd.read_csv(\"surveys.csv\", keep_default_na=False, na_values=[\"\"])\n",
    "\n",
    "survey_sub= survey_sub.head(100)\n",
    "\n",
    "# survey_sub\n",
    "# species_sub\n",
    "\n",
    "# merged_inner= pd.merge(left=survey_sub,right=species_sub, left_on='species', right_on='species_id')\n",
    "# merged_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left joins\n",
    "\n",
    "What if we want to add information from `species_sub` to `survey_sub` without\n",
    "losing any of the information from `survey_sub`? In this case, we use a different\n",
    "type of join called a \"left outer join\", or a \"left join\".\n",
    "\n",
    "Like an inner join, a left join uses join keys to combine two DataFrames. Unlike\n",
    "an inner join, a left join will return *all* of the rows from the `left`\n",
    "DataFrame, even those rows whose join key(s) do not have values in the `right`\n",
    "DataFrame.  Rows in the `left` DataFrame that are missing values for the join\n",
    "key(s) in the `right` DataFrame will simply have null (i.e., NaN or None) values\n",
    "for those columns in the resulting joined DataFrame.\n",
    "\n",
    "Note: a left join will still discard rows from the `right` DataFrame that do not\n",
    "have values for the join key(s) in the `left` DataFrame.\n",
    "\n",
    "![Left Join](http://blog.codinghorror.com/content/images/uploads/2007/10/6a0120a85dcdae970b01287770273e970c-pi.png)\n",
    "\n",
    "A left join is performed in pandas by calling the same `merge` function used for\n",
    "inner join, but using the `how='left'` argument:\n",
    "\n",
    "```python\n",
    "merged_left = pd.merge(left=survey_sub,right=species_sub, how='left', left_on='species_id', right_on='species_id')\n",
    "\n",
    "merged_left\n",
    "\n",
    "**OUTPUT:**\n",
    "\n",
    "   record_id  month  day  year  plot_id species_id sex  hindfoot_length  \\\n",
    "0          1      7   16  1977        2         NL   M               32   \n",
    "1          2      7   16  1977        3         NL   M               33   \n",
    "2          3      7   16  1977        2         DM   F               37   \n",
    "3          4      7   16  1977        7         DM   M               36   \n",
    "4          5      7   16  1977        3         DM   M               35   \n",
    "5          6      7   16  1977        1         PF   M               14   \n",
    "6          7      7   16  1977        2         PE   F              NaN   \n",
    "7          8      7   16  1977        1         DM   M               37   \n",
    "8          9      7   16  1977        1         DM   F               34   \n",
    "9         10      7   16  1977        6         PF   F               20   \n",
    "\n",
    "   weight       genus   species    taxa  \n",
    "0     NaN     Neotoma  albigula  Rodent  \n",
    "1     NaN     Neotoma  albigula  Rodent  \n",
    "2     NaN   Dipodomys  merriami  Rodent  \n",
    "3     NaN   Dipodomys  merriami  Rodent  \n",
    "4     NaN   Dipodomys  merriami  Rodent  \n",
    "5     NaN         NaN       NaN     NaN  \n",
    "6     NaN  Peromyscus  eremicus  Rodent  \n",
    "7     NaN   Dipodomys  merriami  Rodent  \n",
    "8     NaN   Dipodomys  merriami  Rodent  \n",
    "9     NaN         NaN       NaN     NaN  \n",
    "```\n",
    "\n",
    "The result DataFrame from a left join (`merged_left`) looks very much like the\n",
    "result DataFrame from an inner join (`merged_inner`) in terms of the columns it\n",
    "contains. However, unlike `merged_inner`, `merged_left` contains the **same\n",
    "number of rows** as the original `survey_sub` DataFrame. When we inspect\n",
    "`merged_left`, we find there are rows where the information that should have\n",
    "come from `species_sub` (i.e., `species_id`, `genus`, and `taxa`) is\n",
    "missing (they contain NaN values):\n",
    "\n",
    "```python\n",
    "merged_left[ pd.isnull(merged_left.genus) ]\n",
    "**OUTPUT:** \n",
    "   record_id  month  day  year  plot_id species_id sex  hindfoot_length  \\\n",
    "5          6      7   16  1977        1         PF   M               14   \n",
    "9         10      7   16  1977        6         PF   F               20   \n",
    "\n",
    "   weight genus species taxa  \n",
    "5     NaN   NaN     NaN  NaN  \n",
    "9     NaN   NaN     NaN  NaN\n",
    "```\n",
    "\n",
    "These rows are the ones where the value of `species_id` from `survey_sub` (in this\n",
    "case, `PF`) does not occur in `species_sub`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.merge(left=survey_sub,right=species_sub, how='left', left_on='species_id', right_on='species_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other join types\n",
    "\n",
    "The pandas `merge` function supports two other join types:\n",
    "\n",
    "* Right (outer) join: Invoked by passing `how='right'` as an argument. Similar\n",
    "  to a left join, except *all* rows from the `right` DataFrame are kept, while\n",
    "  rows from the `left` DataFrame without matching join key(s) values are\n",
    "  discarded.\n",
    "* Full (outer) join: Invoked by passing `how='outer'` as an argument. This join\n",
    "  type returns the all pairwise combinations of rows from both DataFrames; i.e.,\n",
    "  the result DataFrame will `NaN` where data is missing in one of the dataframes. This join type is\n",
    "  very rarely used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Challenges\n",
    "\n",
    "## Challenge 1\n",
    "Create a new DataFrame by joining the contents of the `surveys.csv` and\n",
    "`species.csv` tables. Then calculate and plot the distribution of:\n",
    "\n",
    "1. taxa by plot\n",
    "2. taxa by sex by plot\n",
    "\n",
    "## Challenge 2\n",
    "\n",
    "1. In the data folder, there is a plot `CSV` that contains information about the\n",
    "   type associated with each plot. Use that data to summarize the number of\n",
    "   plots by plot type. \n",
    "2. Calculate a diversity index of your choice for control vs rodent exclosure\n",
    "   plots. The index should consider both species abundance and number of\n",
    "   species. You might choose to use the simple [biodiversity index described\n",
    "   here](http://www.amnh.org/explore/curriculum-collections/biodiversity-counts/plant-ecology/how-to-calculate-a-biodiversity-index)\n",
    "   which calculates diversity as:\n",
    "\n",
    "        the number of species in the plot / the total number of individuals in the plot = Biodiversity index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
